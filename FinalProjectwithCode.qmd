---
title: "Data Science for Public Policy"
subtitle: "Final Project"
author: "Asad Azhar, Juan Menendez, Priscila Stisman, Talia Stringfellow"
execute:
  warning: false
format:
  html:
    embed-resources: true
---
## Final Project Studying Latin America

# Packages
```{r}
library(tidyverse)
library(tidymodels)
library(recipes)
library(ggplot2)
library(ggrepel)
library(patchwork)
library(tidyclust)
library(dplyr)
library(themis)
library(haven)
library(rpart)
library(lubridate)
library(archive)
library(utils)
library(tigris)
library(sf)
library(geodata)
library(rnaturalearth)
library(mapview)
library(textrecipes) 
library(vip)
library(themis)
library(here)
library(glmnet)
library(ranger)

library(rsample)
library(parsnip)
library(workflows)
library(tune)
library(yardstick)

library(rgeoboundaries)
library(readxl)
library(scales)

library(geobr)
library(spData)
library(ggrepel)
library(colorspace)
library(paletteer)
library(RColorBrewer)
```

# Read in Data

```{r}
lat_am_pop_2023 <- read_dta("Merge_2023_LAPOP_AmericasBarometer_v1.0_w.dta")
```

## Data cleaning

In this section, we identify and clean our variables of intrest

Variables of interest:

[**Etnicity/ skin color identification**]{.underline}

Colorr: contains individual skintone on a scale form 0 to 11 (categorical)

Colori: interviewer skincolor

Etid: self perceived ethnicity (categorical)

[**Employment Status**]{.underline}

Ocup4a: employment status (dummy)

formal: formal job (dummy)

[**Social Capital**]{.underline} 

cp13: political party meetings attendance (frequency of attendance, categorical)

cp8: community meetings attendance (frequency of attendance, categorical)

r4a: has a mobile phone (dummy)

smedia1n: has social media (dummy)

[**Demographic Data**]{.underline}

q1tc_r: sex (make dummy)

q2: age (continuous)

q12cn: number of members in the household

q10inc: income (Argentine pesos, categorical) (for Argentina)

Edre: education attainment (all levels)

pais : country (numeric)

```{r}

Workingdata <- lat_am_pop_2023 %>% select(colorr, colori, etid, ocup4a, formal, cp13, cp8, r4a, smedia1n, q1tc_r, q2, q12cn, q10inc, edre, pais, ur, q14, q14motan, prov)

#creating dummy for work status where 1 is working and zero is not working 
Workingdata <- Workingdata %>%
  mutate(ocup4a = case_when(
    ocup4a == 1 ~ 1,
    ocup4a == 2 ~ 0,
    ocup4a == 3 ~ 0,
    ocup4a == 4 ~ 0,
    ocup4a == 5 ~ 0,
    ocup4a == 6 ~ 0,
    ocup4a == 7 ~ 0,
    TRUE ~ NA
  ))

#cleaning skin color (self identified) 
Workingdata <- Workingdata %>%
  mutate(colorr = case_when(
    colorr == 1 ~ 1,
    colorr == 2 ~ 2,
    colorr == 3 ~ 3,
    colorr == 4 ~ 4,
    colorr == 5 ~ 5,
    colorr == 6 ~ 6,
    colorr == 7 ~ 7, 
    colorr == 8 ~ 8,
    colorr == 9 ~ 9,
    colorr == 10 ~ 10,
    colorr == 11 ~ 11, 
    colorr == 97 ~ NA, 
    TRUE ~ NA
  ))

#cleaning formal vs informal work 
Workingdata <- Workingdata %>%
  mutate(formal = case_when(
    formal == 1 ~ 1,
    formal == 2 ~ 0,
    TRUE ~ NA
  ))

#cleaning uses social media indicator variable
Workingdata <- Workingdata %>%
  mutate(smedia1n = case_when(
    smedia1n == 1 ~ 1,
    smedia1n == 2 ~ 0,
    TRUE ~ NA
  ))


#cleaning political involvement to be least to most 
Workingdata <- Workingdata %>%
  mutate(cp13 = case_when(
    cp13 == 4 ~ 1,
    cp13 == 3 ~ 2,
    cp13 == 2 ~ 3,
    cp13 == 1 ~ 4,
    TRUE ~ NA
  ))

#cleaning community involvement to be least to most 
Workingdata <- Workingdata %>%
  mutate(cp8 = case_when(
    cp8 == 4 ~ 1,
    cp8 == 3 ~ 2,
    cp8 == 2 ~ 3,
    cp8 == 1 ~ 4,
    TRUE ~ NA
  ))

#cleaning urban indicator variable
Workingdata <- Workingdata %>%
  mutate(ur = case_when(
    ur == 1 ~ 1,
    ur == 2 ~ 0,
    TRUE ~ NA
  ))

#making gender indicator variable where 0 = female, 1 = male
Workingdata <- Workingdata %>%
  mutate(q1tc_r = case_when(
    q1tc_r == 1 ~ 1,
    q1tc_r == 2 ~ 0,
    q1tc_r == 3 ~ NA,
  ))

#cleaning ethnicity (note there is no etid6, etid7 is "other" so we will convert all the additional races as "other" for simplicity)
#making black the max instead of mulata

Workingdata <- Workingdata %>%
  mutate(etid = case_when(
    etid == 1 ~ 1, 
    etid == 2 ~ 2, 
    etid == 3 ~ 3, 
    etid == 5 ~ 4, 
    etid == 4 ~ 5, 
    etid > 200 ~ 7,
    etid == 7 ~ 7, 
    TRUE ~ NA
  ))

#creating labels for ethnicity 
ethnicity_labels <- c(
  "White" = 1,
  "Mestizo" = 2,
  "Indigenous" = 3,
   "Mulata" = 4, #note that this was orignially coded as 5 and Black as 4, they have been switched 
   "Black" = 5,
  "Other" = 7, 
  "No Data" = NA
)

#creating ethnicity codes 
ethnicity_codes <- c(1, 2, 3, 4, 5, 7)

# create indicator variable for getting to university (includes partial and completion of university)
Workingdata <- Workingdata %>%
  mutate(university = case_when(
    edre == 6 ~ 1,
    edre == 5 ~ 1,
    !(edre %in% c(5, 6)) ~ 0,
    TRUE ~ NA
  ))

#creating a factor variable for getting into university  
Workingdata <- Workingdata %>%
  mutate(university_factor = factor(case_when(
    edre == 6 ~ "University",
    edre == 5 ~ "University", 
    !(edre %in% c(5, 6)) ~ "Non-University", 
    TRUE ~ NA_character_ 
  )))

#cleaning q14 which asks about considering emigrating in the next 3 years
Workingdata <- Workingdata %>%
  mutate(q14 = case_when(
    q14 == 1 ~ 1,
    q14 == 2 ~ 0,
    TRUE ~ NA,
  ))

#creating indicator variable for stating "Lack of educational opportunities" as reason for why they have considered emigrating 
Workingdata <- Workingdata %>%
  mutate(leave4educ = case_when(
    q14motan == 3 ~ 1,
    !(q14motan %in% 3) ~ 0,
    TRUE ~ NA
  ))

#cleaning Income for ARGENTINA ONLY 
arg_income_codes <- c(1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715)

# Labels for ARGENITNA INCOME 
arg_income_labels <- c("Between $0 and $14.000 pesos", "Between $14.001 and $26.000 pesos", "Between $26.001 and $39.000 pesos",
            "Between $39.001 and $47.000 pesos", "Between $47.001 and $55.000 pesos", "Between $55.001 and $61.000 pesos",
            "Between $61.001 and $68.000 pesos", "Between $68.001 and $81.000 pesos", "Between $81.001 and $88.000 pesos",
            "Between $88.001 and $97.000 pesos", "Between $97.001 and $115.000 pesos", "Between $115.001 and $136.000 pesos",
            "Between $136.001 and $168.000 pesos", "Between $168.001 and $221.000 pesos", "More than $221.000 pesos")

# Assign labels FOR ARGENTINA INCOME 
arg_income_values <- factor(arg_income_codes, levels = arg_income_codes, labels = arg_income_labels)

#cleaning Income for BRAZIL ONLY 
#arg_income_codes <- c(1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715)

# Labels for BRAZIL INCOME 
#arg_income_labels <- c("Between $0 and $14.000 pesos", "Between $14.001 and $26.000 pesos", "Between $26.001 and $39.000 pesos",
           # "Between $39.001 and $47.000 pesos", "Between $47.001 and $55.000 pesos", "Between $55.001 and $61.000 pesos",
         #   "Between $61.001 and $68.000 pesos", "Between $68.001 and $81.000 pesos", "Between $81.001 and $88.000 pesos",
          #  "Between $88.001 and $97.000 pesos", "Between $97.001 and $115.000 pesos", "Between $115.001 and $136.000 pesos",
          #  "Between $136.001 and $168.000 pesos", "Between $168.001 and $221.000 pesos", "More than $221.000 pesos")

# Assign labels FOR BRAZIL INCOME 
#arg_income_values <- factor(income_codes, levels = income_codes, labels = income_labels)

#Adding country labels 
Workingdata <- Workingdata %>% 
  filter(pais < 39) %>% #getting rid of US and Canada from dataset 
  mutate(country_name = factor(case_when(
    pais == 1 ~ "Mexico",
    pais == 2 ~ "Guatemala", 
    pais == 3 ~ "El Salvador",
    pais == 4 ~ "Honduras", 
    pais == 5 ~ "Nicaragua",
    pais == 6 ~ "Costa Rica", 
    pais == 7 ~ "Panama",
    pais == 8 ~ "Colombia", 
    pais == 9 ~ "Ecuador",
    pais == 10 ~ "Bolivia", 
    pais == 11 ~ "Peru", 
    pais == 12 ~ "Paraguay",
    pais == 13 ~ "Chile", 
    pais == 14 ~ "Uruguay",
    pais == 15 ~ "Brazil", 
    pais == 16 ~ "Venezuela",
    pais == 17 ~ "Argentina", 
    pais == 21 ~ "Dominican Republic", 
    pais == 22 ~ "Haiti", 
    pais == 23 ~ "Jamaica",
    pais == 24 ~ "Guyana", 
    pais == 25 ~ "Trinidad & Tobago",     
    pais == 26 ~ "Belize",
    pais == 27 ~ "Suriname", 
    pais == 28 ~ "Bahamas", 
    pais == 29 ~ "Barbados",
    pais == 30 ~ "Grenada", 
    pais == 31 ~ "Saint Lucia", 
    pais == 32 ~ "Dominica", 
    pais == 33 ~ "Antigua and Barbuda", 
    pais == 34 ~ "Saint Vincent and the Grenadines", 
    pais == 35 ~ "Saint Kitts and Nevis",
    TRUE ~ NA_character_ 
  ))) %>%
  relocate(country_name, .after = pais) 

Workingdata <- Workingdata %>%
  rename(skin_color = colorr,
         ethnicity = etid,
         employed = ocup4a,
         mobile = r4a, 
         social_media = smedia1n,
         male = q1tc_r,
         age = q2, 
         income = q10inc,
         educ_attainment = edre,
         political_involvement = cp13,
         community_involvement  =cp8, 
         country_num = pais)


SouthAmerica_only <- Workingdata %>% 
  filter(country_name == "Argentina" 
         | country_name == "Uruguay" 
         | country_name == "Chile" 
         | country_name == "Paraguay" 
         | country_name == "Bolivia" 
         | country_name == "Peru" 
         | country_name == "Ecuador" 
         | country_name == "Brazil" 
         | country_name == "Suriname" 
         | country_name == "Guyana" 
         | country_name == "French Guiana"  
         | country_name == "Venezuela" 
         | country_name == "Colombia")

```

## Missing Values Assessment and Imputing
We use Library missRanger for imputing missing values. The "ranger" package (Wright & Ziegler) is helpful to do fast missing value imputation by chained random forests, see Stekhoven & Buehlmann and Van Buuren & Groothuis-Oudshoorn. Between the iterative model fitting, it offers the option of predictive mean matching. This firstly avoids imputation with values not present in the original data (like a value 0.3334 in a 0-1 coded variable). Secondly, predictive mean matching tries to raise the variance in the resulting conditional distributions to a realistic level. This allows to do multiple imputation when repeating the call to missRanger().

References
1. Wright, M. N. & Ziegler, A. (2016). ranger: A Fast Implementation of Random Forests for
High Dimensional Data in C++ and R. Journal of Statistical Software, in press. <arxiv.org/abs/1508.04409>.
2. Stekhoven, D.J. and Buehlmann, P. (2012). ’MissForest - nonparametric missing value impu-
tation for mixed-type data’, Bioinformatics, 28(1) 2012, 112-118. https://doi.org/10.1093/bioinformatics/btr597.
3. Van Buuren, S., Groothuis-Oudshoorn, K. (2011). mice: Multivariate Imputation by Chained Equations in R. Journal of Statistical Software, 45(3), 1-67. http://www.jstatsoft.org/v45/i03/
```{r}
# Check for missing values
missing_values <- sum(is.na(Workingdata))
if (missing_values > 0) {
  cat("There are", missing_values, "missing values in the dataset.\n")
  # Handle missing values here (e.g., imputation or other preprocessing steps)
} else {
  cat("No missing values found in the dataset.\n")
}

#There are 122946 missing values in the dataset

#Imputing missing values with MissRanger
Workingdata <- missRanger(Workingdata, num.trees = 30, num.threads = 2)
summary(Workingdata)

#No Missing values found in the dataset

```

## Exploritory Data Analysis 

## Geospatial data upload 
```{r}

data("world")

sa_all_mapping <- world %>%
  filter(continent == "South America") 

#need to take out countries that are not in the other datasets: Falkland Islands, Venezuela, Guyana, French Guiana 
sa_mapping <- sa_all_mapping %>%
  filter(name_long != "Falkland Islands" & name_long != "Venezuela" & name_long != "Guyana")

#province level data for each country 
geoboundaries <- gb_adm1() %>%
  filter(shapeGroup %in% c("ARG", "COL", "BRA", "URY", "CHL", "VEN", "PRY", "PER", "ECU", "SUR", "GUY", "GUF", "BOL")) 


#Argentina province level data
arg <- gb_adm1("ARG")

#mapping argentina 
plot(st_geometry(arg),
     col = rgb(red = 1, green = 0, blue = 0, alpha = 0.5),
     axes = TRUE, graticule = TRUE)

#exploring other geospatial data on south america 
library(remotes)
remotes::install_github("wmgeolab/rgeoboundaries")
library(rgeoboundaries)

#Pulling Argentina specific data 
Argentina <- geoboundaries(
     country = "Argentina",
     adm_lvl = "adm1",
     type = "simplified") 
Argentina <- geoboundaries(
     country = "Argentina",
     adm_lvl = "adm1",
     type = "simplified") 
 

#mapping south america by population 
pop_geom <- sa_all_mapping %>%
  ggplot() +
  geom_sf(aes(fill=pop/10^6), color = "brown", size = 0.1) +
  ggrepel::geom_label_repel(aes(label = name_long, geometry = geom),
    stat = "sf_coordinates",
    min.segment.length = 0,
    size = 3,
    color = "black") + 
  scale_fill_continuous_sequential(palette= "Heat 2")+
    labs(title = "Population by Country\nin Millions of Inhabitants", fill= "Pop.\n(in millions)")+
  theme_void() +
    theme(legend.title=element_text(size=9), 
          plot.title = element_text(face = "bold", hjust = 0.5),
          plot.title.position = "plot")


#mapping South America by Life Expectancy 
le_geom <- sa_all_mapping %>%
  ggplot()+
  geom_sf(aes(fill = lifeExp), color = "brown", size = 0.1) +
  ggrepel::geom_label_repel(aes(label = round(lifeExp),2, geometry = geom),
    stat = "sf_coordinates",
    min.segment.length = 0,
    size = 3,
    color = "black") + 
  scale_fill_continuous_sequential(palette= "Heat 2")+
  labs(title = "Average Life Expenctancy by Country", fill = "Life Expectancy\n(in years)") +
  theme_void() +
    theme(legend.title=element_text(size=9),
          plot.title = element_text(face = "bold", hjust = 0.5),
          plot.text = element_text(face = "bold"),
          plot.title.position = "plot")

#side by side:
pop_geom + le_geom 


```

Here we are conducting some basic analysis of how South America maps given basic country level statistics. We see that Chile stands out with the highest life expectancy and somewhat smaller relative population. Brazil has the largest population by far with over 200 million people and has the median south American life expectancy of 75 years. 

Please note this is not data from the LAPOP survey data, but rather best estimates of the true population size and life expectancy based on census / larger scale data from the geoboundaries Rpackage. 

```{r}
#Investigating age distributions by country visually 
SouthAmerica_only %>%
  ggplot(aes(age, fill = country_name)) +
  geom_bar() +
  facet_wrap(~country_name, scales = "free") +
  labs(fill = "Country Name", title = "Age distribution of Data by Country", x = "Age (years)", y = "Count from Survey") +
  theme_minimal() +
    theme(legend.title=element_text(size=9),
          plot.title = element_text(face = "bold", hjust = 0.5),
          plot.title.position = "plot")
```
Based on this survey data, we observe that most South American countries have relatively young population pyramids, with a demographic dividend estimated break even around 2035. Uruguay stands out as a country with a somewhat evenly distributed age distribution and with the most elderly people surveyed.

```{r}
#seeing how much of our data set has considered emigrating for educational attainment purposes (very low at less than 1%)

SouthAmerica_only %>%
  filter(q14 == 1)%>%
  summarise(mean(leave4educ))

```

Part of the survey was asking respondents "And what is the most important reason why you have thought about emigrating?" with the option of "Lack of educational opportunities". We observe that of the people that responded yes to wanting to emigrate in the next 3 years, only a very small portion (0.4%) of the surveyed population noted it as a cause for emigration. Leading us to believe that lack of educational opportunities within one's home country is not a main driver of educational access.  

## Transforming Ethnicity Results of Survey to Country Level 
```{r}
#creating table that counts the ethnicity breakout by country 
countryxeth_tbl <- SouthAmerica_only %>%
  group_by(country_name, ethnicity) %>%
  count(ethnicity) %>%
  pivot_wider(names_from = ethnicity, values_from = n) %>%
  ungroup()

countrylevel_eth_df <- as.data.frame(countryxeth_tbl)

#replacing missing values with zero
countrylevel_eth_df <- within(countrylevel_eth_df, {
  `2` <- replace(`2`, is.na(`2`), 0)
  `3` <- replace(`3`, is.na(`3`), 0)
  `5` <- replace(`5`, is.na(`5`), 0)
})

#create a total column 
countrylevel_eth_df$total_pop <- rowSums(countrylevel_eth_df[, c('1', '2', '3', '4', '5', '7', 'NA')])

countrylevel_eth_df
```

```{r}
#create a proportions ethnicity df out of the raw data 
eth_proportions_df <- countrylevel_eth_df %>%
  group_by(country_name) %>%
  mutate("1" = `1` / total_pop *100,
         "2"= `2` / total_pop *100,
         "3" = `3` / total_pop *100,
         "4" = `4` / total_pop *100,
         "5"= `5` / total_pop *100,
         "7" = `7` / total_pop *100,
         "NA" = `NA` / total_pop *100) %>%
  ungroup()

eth_proportions_df
#data not showing 3 countries: Venezuela, Guyana, French Guiana

#Pivoting the ethnicity proportions longer so that I can interpret with bargraphs 
eth_prop_df_long <-eth_proportions_df %>%
  select(-total_pop) %>%
  pivot_longer(!country_name, names_to = "ethnicity", values_to = "percent")

#adding ethnicity labels to dataframe 
eth_prop_df_long <- eth_prop_df_long %>%
  mutate(eth_lab = case_when(
    ethnicity == 1 ~ "White",
    ethnicity == 2 ~ "Mestizo",
    ethnicity == 3 ~ "Indigenous",
    ethnicity == 4 ~ "Mulata",
    ethnicity == 5 ~ "Black",
    ethnicity == 7 ~ "Other",
    is.na(ethnicity) ~ "No Data"
  ))

eth_prop_df_long 

#creating a bar graph with the ethnicity proportions 
eth_prop_bargraph <- eth_prop_df_long %>%
  ggplot(aes(x = country_name, y = percent, fill = eth_lab)) +
  geom_bar(position = position_fill(reverse = TRUE), stat = "identity") +
  labs(title = "Ethnicity Category as Proportion by Country", caption = "From Representative sample from LAPOP in 2023", y = "Percent", x = "Country", fill = "Ethnicity") +
  scale_fill_brewer(palette = "BrBG", na.value = "orange")+ 
  theme_minimal() +
  theme(legend.title=element_text(face = "bold"),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(face = "italic", hjust = 0.5),
        plot.title.position = "plot")

#use scales - categorical variable - fill manual and set colors with palette 
#scale_fill_manual (vector with categories, colors with hex codes)

```

## Transforming Educational Attainment Results of Survey to Country Level 
```{r}
#creating table that counts the education breakout by country 
countryxeduc_tbl <- SouthAmerica_only %>%
  group_by(country_name, educ_attainment) %>%
  count(educ_attainment) %>%
  pivot_wider(names_from = educ_attainment, values_from = n) %>%
  ungroup()

countryxeduc_tbl

#replacing missing values with zero
countryxeduc_tbl <- within(countryxeduc_tbl, {
  `NA` <- replace(`NA`, is.na(`NA`), 0)
})

#creating a total without NA column
countryxeduc_tbl$total_pop_noNA <- rowSums(countryxeduc_tbl[, c('0', '1', '2', '3', '4', '5', '6')])

#create a total column with NA
countryxeduc_tbl$total_pop_withNA <- rowSums(countryxeduc_tbl[, c('0', '1', '2', '3', '4', '5', '6', 'NA')])

countryxeduc_tbl

#create a proportions ethnicity df out of the raw data 
educ_proportions_df <- countryxeduc_tbl %>%
  group_by(country_name) %>%
  mutate("0" = `0` / total_pop_withNA *100,
         "1" = `1` / total_pop_withNA *100,
         "2"= `2` / total_pop_withNA *100,
         "3" = `3` / total_pop_withNA *100,
         "4" = `4` / total_pop_withNA *100,
         "5"= `5` / total_pop_withNA *100,
         "6" = `6` / total_pop_withNA *100,
         "NA" = `NA` / total_pop_withNA *100) %>%
  ungroup()

educ_proportions_df
#data not showing 3 countries: Venezuela, Guyana, French Guiana

#prepping education proportions df for graphing 
educ_prop_df_long <-educ_proportions_df %>%
  select(-total_pop_noNA, -total_pop_withNA) 

educ_prop_df_long  
#Pivoting the ethnicity proportions longer so that I can interpret with bargraphs 
educ_prop_df_long <-educ_prop_df_long %>%
  pivot_longer(!country_name, names_to = "educ_score", values_to = "percent")

#adding labels for education 
educ_prop_df_long <- educ_prop_df_long %>%
  mutate(educ_lab = case_when(
    educ_score == 0 ~ "None",
    educ_score == 1 ~ "Primary School Incomplete",
    educ_score == 2 ~ "Primary School Complete",
    educ_score == 3 ~ "High-school Incomplete",
    educ_score == 4 ~ "High-school Complete",
    educ_score == 5 ~ "Tertiary/University Incomplete",
    educ_score == 6 ~ "Tertiary/University Complete",
    is.na(educ_score) ~ "No Data"
  ))
  
  
  #educ_lab = factor(educ_lab, levels = c("None", "Primary School Incomplete", "Primary School Complete", "High-school Incomplete", "High-school Complete", "Tertiary/University Incomplete", "Tertiary/University Complete", "No Data")))

educ_prop_df_long 

#creating a bar graph with the ethnicity proportions 
educ_prop_bargraph <- educ_prop_df_long %>%
  ggplot(aes(x = country_name, y= percent, fill = educ_score)) +
  geom_bar(position = position_fill(reverse = TRUE), stat="identity") + 
  labs(title = "Educational Outcome Distribution by Country", caption = "From Representative sample from LAPOP in 2023\n 'Pri Sch' means Primary School, 'HS' stands for High School,\n'Uni' stands for University, 'Inc' & 'Comp' stands for in/complete", 
       fill = "Educ level\n(categorical)", y = "Percent", x = "Country") +
  scale_fill_manual(labels = 
                        c("None", "Pri Sch Inc.", "Pri Sch Comp.", 
                          "HS Inc.", "HS Comp.", 
                          "Uni Inc.", "Uni Comp.", "No Data"), values = c("#C2E6C7", "#9FD99E", "#7BC47F", "#4CAF50", "#388E3C", "#2E7D32", "#1B5E20", "#333333")) +
  theme_minimal() +
  theme(legend.title=element_text(face = "bold"),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(face = "italic", hjust = 0.5),
        plot.title.position = "plot")

#putting the graphs on top of each other 
(eth_prop_bargraph / educ_prop_bargraph) + plot_layout(nrow = 2, heights = c(1, 1))
```


```{r}
#finding mean educational outcome by country
countryxeduc_tbl <- countryxeduc_tbl %>%
  group_by(country_name) %>%
  mutate(mean_education = (0*`0` + 1*`1` + 2*`2` + 3*`3`+ 4*`4` + 5*`5` + 6*`6`)/total_pop_noNA) 

#adding mean education outcome to our geospatial data (sa_mapping)
#ONLY RUN THIS CODE ONCE! 
sa_mapping <- sa_mapping %>%
  left_join(countryxeduc_tbl, by = c("name_long" = "country_name")) %>%
  select(-matches("\\d+"), -`NA`)

#renameing total pop because it's the survey population not the real population! 
sa_mapping <- sa_mapping %>%
  rename(survey_total_noNA = total_pop_noNA) %>%
  rename(survey_total_withNA = total_pop_withNA)

#Visualizing the Mean population outcomes 
#mapping South America by mean educational outcome 
educ_geom <-sa_mapping %>%
  ggplot()+
  geom_sf(aes(fill = mean_education), color = "white", size = 0.1) +
   ggrepel::geom_label_repel(aes(label = round((mean_education),2), geometry = geom),
    stat = "sf_coordinates",
    min.segment.length = 0,
    size = 3,
    color = "black") + 
  scale_fill_gradient(name = "Avg. Educ\non scale of \n0 to 6", 
                      low = "#C0D8FD", high = "#0F6CFC") +
  labs(title = "Average Educational Outcome \nin South America", subtitle = "using representative data", caption = "Education is categorized based on an increasing \neducational achievement. Variables are coded as follows:\nNone = 0,\nPrimary School Incomplete = 1\nPrimary School Complete = 2\nHigh-school Incomplete = 3\nHigh-school Complete = 4\nTertiary/University Incomplete = 5\nTertiary/University Complete = 6") +
  theme_void() +
  theme(plot.caption = element_text(face = "italic", hjust = 0, size =7),
        legend.title = element_text(size =9),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.subtitle = element_text(face = "italic", hjust = 0.5, size = 8),
        plot.title.position = "plot")


#mapping South America by GDP per Capita 
gdp_geom <- sa_mapping %>%
  ggplot()+
  geom_sf(aes(fill = gdpPercap), color = "white", size = 0.1) +
  scale_fill_gradient(name = "GDP\n(per Capita)", 
                      low = "#C0D8FD", high = "#0F6CFC",
                      labels = scales::dollar)+
  labs(title = "GDP per Capita \nin South America", caption = "Findings from representative\nsurvey data 'LAPOP' 2023") +
  theme_void() +
  theme(legend.title=element_text(size =9),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(face = "italic", hjust = 0.5, size =7),
        plot.title.position = "plot")

#side by side:
educ_geom + gdp_geom 

```

```{r}
#creating table that counts education breakout by ethnicity 
educxeth_tbl <- SouthAmerica_only %>%
  group_by(ethnicity, educ_attainment) %>%
  count(educ_attainment) %>%
  pivot_wider(names_from = ethnicity, values_from = n) %>%
  ungroup()

educxeth_tbl

#making data factors:
SouthAmerica_only <- SouthAmerica_only %>%
  mutate_at(vars(-age, -income), as.factor)

```

```{r}
skincolor <- c("#fff5f6", "#f5e2dc", "#e9c1b7", "#e7c9a5", "#c0a280", "#9d7c53", "#85674f", "#70503b", "#523c2f", "#422811", "#383127")
skincodes <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)
skincolorpalette <- tibble(skincodes, skincolor)

ggplot(SouthAmerica_only, aes(x = factor(skin_color))) +
  geom_bar(aes(fill = factor(skin_color))) +  # Fill mapped to colorr
  scale_fill_manual(values = skincolor) +
  labs(title = "Self-reported skin color", x = "Skin color (from lighter to darker)", y = "Number of Individuals from the sample", fill="Skin Color", caption = "Findings from representative survey data 'LAPOP' 2023,\nrespondents where asked to self-report their skin color.")+
  theme_minimal() +
  theme(legend.title=element_text(size =9),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(face = "italic", hjust = 0.5, size =7),
        plot.title.position = "plot")

```

## Splitting the data 
```{r}
#setting seed 
set.seed(20201020)

# create a split object
data_splitting <- initial_split(data = SouthAmerica_only, prop = 0.75)
# create the training and testing data
data_train <- training(x = data_splitting)
data_test <- testing(x = data_splitting)

```

#### PRISCILA HERE:

```{r fig.height=10, fig.width=12}

ggplot(data_train, aes(skin_color, fill = factor(educ_attainment, levels = 0:6))) +
  geom_bar(position = "dodge") +
    scale_x_discrete(labels = names(skincolor)) +
  scale_fill_hue(labels = c("None",
                             "Primary School Incomplete",
                             "Primary School Complete",
                             "High-school Incomplete",
                             "High-school Complete",
                             "Tertiary/University Incomplete",
                             "Tertiary/University Complete")) +
  facet_wrap(~ country_name, nrow = 2) +  # Create separate plots for each country
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(fill = "Education Attainment") +
  ggtitle("Education Attainment by Skin Color and Country")

# I think this graph is pretty intuitive of the situation. In the x-axis we measure whiter to darkers skin color, and it is clear for some countries that whiter color skin people have on average more high-school complete and tertiaria/university compared to darker counterparts. This is: blue and pink bars are mostly at the beginning of the x axis.

```


```{r}
#Build decision tree

# Create the recipe object 
tree_recipe <- recipe(formula = university_factor ~ ., data = data_train) %>%
  step_rm("educ_attainment", "university") %>%
  step_normalize(all_numeric_predictors()) %>%
  step_nzv(all_numeric_predictors()) %>%
  step_impute_median(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) 

# Create a cart model object
  tree <- 
  decision_tree() %>%
  set_engine("rpart", model = TRUE) %>%
  set_mode("classification")

# Create a workflow
tree_wf <- workflow() %>%
  add_recipe(tree_recipe) %>%
  add_model(tree) 

# Define the parameter grid
param_grid <- expand.grid(
  min_n = c(2, 5, 10, 15),   # Different values for the minimum number of observations in a node
  maxdepth = c(3, 5, 7, 10)  # Different values for the maximum tree depth
)


# Tune the model
folds <- vfold_cv(data = data_train, v = 10)

tree_tune <- tree_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid,
    control = control_grid(verbose = TRUE),
    metrics = metric_set(accuracy, precision, recall)
  )

# Extract the best tuning parameters
best_params <- tree_tune %>%
  select_best(metric = "accuracy")

# Create a new tree model with the best parameters
best_tree_model <- tree %>%
  set_engine("rpart", model = TRUE) %>%
  set_mode("classification") %>% 
  finalize_model(best_params)

# Fit the tuned model
best_tree_fit <- best_tree_model %>%
  fit(data = data_train, formula = university_factor ~ .)

# create a tree
rpart.plot::rpart.plot(x = best_tree_fit$fit)

```


Logistic Regression
```{r}
# Create a recipe
logistic_recipe <- recipe(formula = university_factor ~ ., data = data_train) %>%
    step_rm("educ_attainment", "university", "country_name") %>%
    step_normalize(all_numeric_predictors()) %>%
    step_nzv(all_numeric_predictors())
             
# Set Logistic Model
logit_model <- logistic_reg() %>%
  set_engine("glm", family = binomial(link = "logit"))

# Logit workflow and recipe
logistic_wf <- workflow() %>%
  add_model(logit_model) %>%
  add_recipe(logistic_recipe)


# Set folds for cross-validation
folds <- vfold_cv(data = data_train, v = 10)

# Fitting Logit model using v-fold resampling method
logistic_fit_rs <- logistic_wf %>%
  fit_resamples(
    resamples = folds,
    control = control_resamples(save_pred = TRUE, save_workflow = TRUE),
    metrics = metric_set(accuracy, precision, recall)
  )
```

KNN
```{r}
#Build KNN Model

knn_recipe <- recipe(formula = university_factor ~ ., data = data_train) %>%
  step_rm("educ_attainment", "university", "country_name") %>%
  step_normalize(all_numeric_predictors()) %>%
  step_nzv(all_numeric_predictors()) %>%
  step_impute_median(all_numeric_predictors())

# create a knn model specification
knn_mod <-
  nearest_neighbor(neighbors = 5) %>%
  set_engine(engine = "kknn") %>%
  set_mode(mode = "classification")

# create workflow

knn_workflow <-
  workflow() %>%
  add_model(spec = knn_mod) %>%
  add_recipe(recipe = knn_recipe)

# fit resamples
set.seed(456)

knn_fit_rs <- knn_workflow %>%
  fit_resamples(resamples = folds)

#evaluate the model
collect_metrics(knn_fit_rs)

```


Lasso
```{r}
data_train <- data_train %>%
  mutate_at(vars(-university_factor, -country_name), as.numeric)

# Create a recipe with mean imputation for missing values
lasso_recipe <- recipe(formula = university ~ ., data = data_train) %>%
    step_rm("educ_attainment", "university_factor", "country_name") %>%
  step_impute_mean(all_predictors())

# Set up the Lasso model specification
lasso_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

# Set the search grid for tuning
lasso_grid <- grid_regular(penalty(range = c(0.01, 1)))

# Create a workflow for Lasso regression with hyperparameter tuning
lasso_wf <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(lasso_recipe)

# Set up the cross-validation
folds <- vfold_cv(data = data_train, v = 10)

# Tune the Lasso model using cross-validation
lasso_tune <- tune_grid(
  object = lasso_wf,
  resamples = folds,
  grid = lasso_grid,
  control = control_grid(verbose = TRUE)
)

# Get the best model
best_model <- select_best(lasso_tune, metric = "rmse")

# Finalize the best-tuned model obtained from tuning
final_lasso_model <- tune::finalize_model(best_model) # THE MODEL STOPS WORKING HERE, TRIED MANY THINS. ASK ALENA please!!!

# Fit the finalized model to the training data
lasso_fit <- final_lasso_model %>%
  fit(data = data_train)

# Extract tuning results
tuning_results <- lasso_tune %>%
  collect_metrics()

# Get the best penalty parameter
best_penalty <- lasso_tune %>%
  select_best("rmse") %>%
  pull(penalty)

# Fitting the best Lasso model using v-fold resampling method
lasso_fit_rs <- lasso_wf %>%
  fit_resamples(
    resamples = folds,
    control = control_resamples(save_pred = TRUE, save_workflow = TRUE),
    metrics = metric_set(accuracy, precision, recall)
  )

```
